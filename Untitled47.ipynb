{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175341, 42)\n",
      "(175341, 25)\n",
      "(175341, 42)\n",
      "(175341, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train=pd.read_csv(r'G:\\Class_project\\New_folder\\A_train_samples.csv')\n",
    "y_train=pd.read_csv(r'G:\\Class_project\\New_folder\\A_train_labels.csv')\n",
    "x_test=pd.read_csv(r'G:\\Class_project\\New_folder\\A_test_samples.csv')\n",
    "y_test=pd.read_csv(r'G:\\Class_project\\New_folder\\A_test_labels.csv')\n",
    "x_train=x_train[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
    "       'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21',\n",
    "       'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28', 'F29', 'F30', 'F31',\n",
    "       'F32', 'F33', 'F34', 'F35', 'F36', 'F37', 'F38', 'F39', 'F40', 'F41',\n",
    "       'F42']]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train_scl = scaler.fit_transform(x_train)\n",
    "x_test_scl = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_scl=to_dataframe(x_train_scl)\n",
    "x_train = pd.DataFrame(data=x_train_scl)\n",
    "x_test=pd.DataFrame(data=x_test_scl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175341 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1   2   3   4   5   6   7   8   9   10\n",
       "0        1   0   0   0   0   0   0   0   0   0\n",
       "1        0   0   0   1   0   0   0   0   0   0\n",
       "2        0   0   1   0   0   0   0   0   0   0\n",
       "3        0   0   0   1   0   0   0   0   0   0\n",
       "4        0   0   0   0   1   0   0   0   0   0\n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "175336   0   0   0   0   0   1   0   0   0   0\n",
       "175337   0   0   0   0   0   0   0   0   1   0\n",
       "175338   0   0   0   0   0   1   0   0   0   0\n",
       "175339   0   0   0   0   0   1   0   0   0   0\n",
       "175340   0   0   0   0   0   1   0   0   0   0\n",
       "\n",
       "[175341 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1=pd.get_dummies(y_train['B'])\n",
    "y_train2=y_train['B']\n",
    "df_train=pd.concat([y_train1,y_train2],axis=1)\n",
    "df_train.drop(['B'],axis=1, inplace=True)\n",
    "\n",
    "y_test1=pd.get_dummies(y_test['Labels'])\n",
    "df_test=pd.concat([y_test,y_test1],axis=1)\n",
    "df_test.drop(['Labels'],axis=1,inplace=True)\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 43-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=42))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.1)))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 175341 samples, validate on 175341 samples\n",
      "Epoch 1/100\n",
      "175341/175341 [==============================] - 6s 33us/step - loss: 1.4311 - accuracy: 0.7117 - val_loss: 2.0640 - val_accuracy: 0.5068\n",
      "Epoch 2/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.7658 - accuracy: 0.7655 - val_loss: 1.4930 - val_accuracy: 0.5871\n",
      "Epoch 3/100\n",
      "175341/175341 [==============================] - 5s 28us/step - loss: 0.6532 - accuracy: 0.7774 - val_loss: 0.9524 - val_accuracy: 0.6624\n",
      "Epoch 4/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.6064 - accuracy: 0.7839 - val_loss: 0.7177 - val_accuracy: 0.7267\n",
      "Epoch 5/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.5792 - accuracy: 0.7887 - val_loss: 0.7414 - val_accuracy: 0.7194\n",
      "Epoch 6/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.5614 - accuracy: 0.7931 - val_loss: 0.6160 - val_accuracy: 0.7694\n",
      "Epoch 7/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.5520 - accuracy: 0.7940 - val_loss: 0.6551 - val_accuracy: 0.7417\n",
      "Epoch 8/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.5414 - accuracy: 0.7971 - val_loss: 0.6532 - val_accuracy: 0.7494\n",
      "Epoch 9/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.5355 - accuracy: 0.7995 - val_loss: 0.6925 - val_accuracy: 0.7355\n",
      "Epoch 10/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.5323 - accuracy: 0.8005 - val_loss: 0.6487 - val_accuracy: 0.7453\n",
      "Epoch 11/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.5277 - accuracy: 0.8015 - val_loss: 0.6443 - val_accuracy: 0.7476\n",
      "Epoch 12/100\n",
      "175341/175341 [==============================] - 4s 26us/step - loss: 0.5218 - accuracy: 0.8035 - val_loss: 0.6189 - val_accuracy: 0.7546\n",
      "Epoch 13/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.5182 - accuracy: 0.8050 - val_loss: 0.6454 - val_accuracy: 0.7503\n",
      "Epoch 14/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.5161 - accuracy: 0.8064 - val_loss: 0.6130 - val_accuracy: 0.7659\n",
      "Epoch 15/100\n",
      "175341/175341 [==============================] - 5s 27us/step - loss: 0.5116 - accuracy: 0.8073 - val_loss: 0.5877 - val_accuracy: 0.7669\n",
      "Epoch 16/100\n",
      "175341/175341 [==============================] - 5s 26us/step - loss: 0.5094 - accuracy: 0.8079 - val_loss: 0.6209 - val_accuracy: 0.7549\n",
      "Epoch 17/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.5075 - accuracy: 0.8089 - val_loss: 0.6449 - val_accuracy: 0.7485\n",
      "Epoch 18/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.5054 - accuracy: 0.8097 - val_loss: 0.6168 - val_accuracy: 0.7583\n",
      "Epoch 19/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.5027 - accuracy: 0.8114 - val_loss: 0.6254 - val_accuracy: 0.7512\n",
      "Epoch 20/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4990 - accuracy: 0.8110 - val_loss: 0.6461 - val_accuracy: 0.7459\n",
      "Epoch 21/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4990 - accuracy: 0.8114 - val_loss: 0.5844 - val_accuracy: 0.7676\n",
      "Epoch 22/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4962 - accuracy: 0.8128 - val_loss: 0.5890 - val_accuracy: 0.7698\n",
      "Epoch 23/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4933 - accuracy: 0.8133 - val_loss: 0.5855 - val_accuracy: 0.7700\n",
      "Epoch 24/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4932 - accuracy: 0.8134 - val_loss: 0.6440 - val_accuracy: 0.7443\n",
      "Epoch 25/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4922 - accuracy: 0.8139 - val_loss: 0.6014 - val_accuracy: 0.7514\n",
      "Epoch 26/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4895 - accuracy: 0.8135 - val_loss: 0.5959 - val_accuracy: 0.7596\n",
      "Epoch 27/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4886 - accuracy: 0.8152 - val_loss: 0.6456 - val_accuracy: 0.7432\n",
      "Epoch 28/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4859 - accuracy: 0.8157 - val_loss: 0.6307 - val_accuracy: 0.7470\n",
      "Epoch 29/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4847 - accuracy: 0.8155 - val_loss: 0.6552 - val_accuracy: 0.7400\n",
      "Epoch 30/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4842 - accuracy: 0.8153 - val_loss: 0.5766 - val_accuracy: 0.7651\n",
      "Epoch 31/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4818 - accuracy: 0.8170 - val_loss: 0.5938 - val_accuracy: 0.7642\n",
      "Epoch 32/100\n",
      "175341/175341 [==============================] - 5s 26us/step - loss: 0.4811 - accuracy: 0.8173 - val_loss: 0.5958 - val_accuracy: 0.7588\n",
      "Epoch 33/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4792 - accuracy: 0.8183 - val_loss: 0.5829 - val_accuracy: 0.7705\n",
      "Epoch 34/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4788 - accuracy: 0.8173 - val_loss: 0.6286 - val_accuracy: 0.7449\n",
      "Epoch 35/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4763 - accuracy: 0.8185 - val_loss: 0.6063 - val_accuracy: 0.7549\n",
      "Epoch 36/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4753 - accuracy: 0.8188 - val_loss: 0.6213 - val_accuracy: 0.7534\n",
      "Epoch 37/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4746 - accuracy: 0.8188 - val_loss: 0.6055 - val_accuracy: 0.7596\n",
      "Epoch 38/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4739 - accuracy: 0.8193 - val_loss: 0.5588 - val_accuracy: 0.7819\n",
      "Epoch 39/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4727 - accuracy: 0.8191 - val_loss: 0.5681 - val_accuracy: 0.7651\n",
      "Epoch 40/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4716 - accuracy: 0.8199 - val_loss: 0.5885 - val_accuracy: 0.7640\n",
      "Epoch 41/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4714 - accuracy: 0.8193 - val_loss: 0.5995 - val_accuracy: 0.7601\n",
      "Epoch 42/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4689 - accuracy: 0.8206 - val_loss: 0.6036 - val_accuracy: 0.7540\n",
      "Epoch 43/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4680 - accuracy: 0.8201 - val_loss: 0.5886 - val_accuracy: 0.7635\n",
      "Epoch 44/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4666 - accuracy: 0.8211 - val_loss: 0.6445 - val_accuracy: 0.7478\n",
      "Epoch 45/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4661 - accuracy: 0.8212 - val_loss: 0.5742 - val_accuracy: 0.7668\n",
      "Epoch 46/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4670 - accuracy: 0.8209 - val_loss: 0.5718 - val_accuracy: 0.7666\n",
      "Epoch 47/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4658 - accuracy: 0.8203 - val_loss: 0.6152 - val_accuracy: 0.7518\n",
      "Epoch 48/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4633 - accuracy: 0.8224 - val_loss: 0.5855 - val_accuracy: 0.7652\n",
      "Epoch 49/100\n",
      "175341/175341 [==============================] - 4s 20us/step - loss: 0.4633 - accuracy: 0.8220 - val_loss: 0.5611 - val_accuracy: 0.7690\n",
      "Epoch 50/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4619 - accuracy: 0.8216 - val_loss: 0.6070 - val_accuracy: 0.7596\n",
      "Epoch 51/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4628 - accuracy: 0.8217 - val_loss: 0.5601 - val_accuracy: 0.7701\n",
      "Epoch 52/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4607 - accuracy: 0.8226 - val_loss: 0.5797 - val_accuracy: 0.7657\n",
      "Epoch 53/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4609 - accuracy: 0.8221 - val_loss: 0.6356 - val_accuracy: 0.7474\n",
      "Epoch 54/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4595 - accuracy: 0.8229 - val_loss: 0.5866 - val_accuracy: 0.7630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4588 - accuracy: 0.8228 - val_loss: 0.5570 - val_accuracy: 0.7726\n",
      "Epoch 56/100\n",
      "175341/175341 [==============================] - 3s 20us/step - loss: 0.4570 - accuracy: 0.8234 - val_loss: 0.5902 - val_accuracy: 0.7623\n",
      "Epoch 57/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4561 - accuracy: 0.8239 - val_loss: 0.6121 - val_accuracy: 0.7543\n",
      "Epoch 58/100\n",
      "175341/175341 [==============================] - 3s 20us/step - loss: 0.4551 - accuracy: 0.8252 - val_loss: 0.5604 - val_accuracy: 0.7738\n",
      "Epoch 59/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4564 - accuracy: 0.8237 - val_loss: 0.6429 - val_accuracy: 0.7523\n",
      "Epoch 60/100\n",
      "175341/175341 [==============================] - 4s 25us/step - loss: 0.4544 - accuracy: 0.8245 - val_loss: 0.5816 - val_accuracy: 0.7658\n",
      "Epoch 61/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4531 - accuracy: 0.8250 - val_loss: 0.6073 - val_accuracy: 0.7578\n",
      "Epoch 62/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4538 - accuracy: 0.8243 - val_loss: 0.5956 - val_accuracy: 0.7630\n",
      "Epoch 63/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4531 - accuracy: 0.8251 - val_loss: 0.6444 - val_accuracy: 0.7466\n",
      "Epoch 64/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4513 - accuracy: 0.8249 - val_loss: 0.5729 - val_accuracy: 0.7655: 0.451\n",
      "Epoch 65/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4513 - accuracy: 0.8254 - val_loss: 0.5419 - val_accuracy: 0.7795\n",
      "Epoch 66/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4507 - accuracy: 0.8252 - val_loss: 0.5742 - val_accuracy: 0.7679\n",
      "Epoch 67/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4500 - accuracy: 0.8258 - val_loss: 0.5592 - val_accuracy: 0.7727\n",
      "Epoch 68/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4481 - accuracy: 0.8264 - val_loss: 0.5669 - val_accuracy: 0.7751\n",
      "Epoch 69/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4483 - accuracy: 0.8265 - val_loss: 0.5721 - val_accuracy: 0.7672\n",
      "Epoch 70/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4488 - accuracy: 0.8254 - val_loss: 0.6065 - val_accuracy: 0.7583\n",
      "Epoch 71/100\n",
      "175341/175341 [==============================] - 4s 20us/step - loss: 0.4490 - accuracy: 0.8259 - val_loss: 0.5448 - val_accuracy: 0.7806\n",
      "Epoch 72/100\n",
      "175341/175341 [==============================] - 4s 25us/step - loss: 0.4480 - accuracy: 0.8255 - val_loss: 0.5627 - val_accuracy: 0.7699\n",
      "Epoch 73/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4468 - accuracy: 0.8262 - val_loss: 0.5689 - val_accuracy: 0.77034460 - ac\n",
      "Epoch 74/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4464 - accuracy: 0.8266 - val_loss: 0.5939 - val_accuracy: 0.7593\n",
      "Epoch 75/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4456 - accuracy: 0.8270 - val_loss: 0.5677 - val_accuracy: 0.7707\n",
      "Epoch 76/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4455 - accuracy: 0.8264 - val_loss: 0.5672 - val_accuracy: 0.7734\n",
      "Epoch 77/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4445 - accuracy: 0.8273 - val_loss: 0.5801 - val_accuracy: 0.7683\n",
      "Epoch 78/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4451 - accuracy: 0.8268 - val_loss: 0.5811 - val_accuracy: 0.7622\n",
      "Epoch 79/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4429 - accuracy: 0.8280 - val_loss: 0.5660 - val_accuracy: 0.7733\n",
      "Epoch 80/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4442 - accuracy: 0.8271 - val_loss: 0.5870 - val_accuracy: 0.7618\n",
      "Epoch 81/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4420 - accuracy: 0.8271 - val_loss: 0.5512 - val_accuracy: 0.7725\n",
      "Epoch 82/100\n",
      "175341/175341 [==============================] - 4s 20us/step - loss: 0.4435 - accuracy: 0.8273 - val_loss: 0.6004 - val_accuracy: 0.7560\n",
      "Epoch 83/100\n",
      "175341/175341 [==============================] - 4s 24us/step - loss: 0.4426 - accuracy: 0.8277 - val_loss: 0.6122 - val_accuracy: 0.7577\n",
      "Epoch 84/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4417 - accuracy: 0.8275 - val_loss: 0.6150 - val_accuracy: 0.7552\n",
      "Epoch 85/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4423 - accuracy: 0.8274 - val_loss: 0.5788 - val_accuracy: 0.7687\n",
      "Epoch 86/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4413 - accuracy: 0.8282 - val_loss: 0.5821 - val_accuracy: 0.7672\n",
      "Epoch 87/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4413 - accuracy: 0.8273 - val_loss: 0.5740 - val_accuracy: 0.7681\n",
      "Epoch 88/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4403 - accuracy: 0.8284 - val_loss: 0.5680 - val_accuracy: 0.7693\n",
      "Epoch 89/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4396 - accuracy: 0.8288 - val_loss: 0.6106 - val_accuracy: 0.7627\n",
      "Epoch 90/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4409 - accuracy: 0.8281 - val_loss: 0.5856 - val_accuracy: 0.7619\n",
      "Epoch 91/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4411 - accuracy: 0.8276 - val_loss: 0.5517 - val_accuracy: 0.7702\n",
      "Epoch 92/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4402 - accuracy: 0.8285 - val_loss: 0.6013 - val_accuracy: 0.7553\n",
      "Epoch 93/100\n",
      "175341/175341 [==============================] - 4s 20us/step - loss: 0.4393 - accuracy: 0.8280 - val_loss: 0.5378 - val_accuracy: 0.7849\n",
      "Epoch 94/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4405 - accuracy: 0.8283 - val_loss: 0.6002 - val_accuracy: 0.7627\n",
      "Epoch 95/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4380 - accuracy: 0.8299 - val_loss: 0.5695 - val_accuracy: 0.7668\n",
      "Epoch 96/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4377 - accuracy: 0.8290 - val_loss: 0.5653 - val_accuracy: 0.7678\n",
      "Epoch 97/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4373 - accuracy: 0.8296 - val_loss: 0.5690 - val_accuracy: 0.7711\n",
      "Epoch 98/100\n",
      "175341/175341 [==============================] - 4s 21us/step - loss: 0.4378 - accuracy: 0.8291 - val_loss: 0.5524 - val_accuracy: 0.7760\n",
      "Epoch 99/100\n",
      "175341/175341 [==============================] - 4s 23us/step - loss: 0.4371 - accuracy: 0.8292 - val_loss: 0.5808 - val_accuracy: 0.772185 - \n",
      "Epoch 100/100\n",
      "175341/175341 [==============================] - 4s 22us/step - loss: 0.4358 - accuracy: 0.8298 - val_loss: 0.5628 - val_accuracy: 0.7697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19e00c46e08>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, df_train,\n",
    "          epochs=100,\n",
    "          batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175341/175341 [==============================] - 4s 21us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5628276901267645, 0.7696659564971924]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test,df_test,batch_size=128)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 5, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=model.predict_classes(x_test)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
