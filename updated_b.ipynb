{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################importing libraries##############################\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96756, 22)\n",
      "(96756, 25)\n",
      "(48377, 22)\n",
      "(48377, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################Reading the csv Files####################################\n",
    "x_train=pd.read_excel(r'class_project\\B_train_samples.xlsx')\n",
    "y_train=pd.read_excel(r'class_project\\B_train_labels.xlsx')\n",
    "x_test=pd.read_excel(r'class_project\\B_test_samples.xlsx')\n",
    "y_test=pd.read_excel(r'class_project\\B_test_labels.xlsx')\n",
    "x_train=x_train[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11',\n",
    "       'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21',\n",
    "       'F22']]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################scaling the training Data######################################\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scl = scaler.fit_transform(x_train)\n",
    "x_test_scl = scaler.transform(x_test)\n",
    "#x_train_scl=to_dataframe(x_train_scl)\n",
    "x_train = pd.DataFrame(data=x_train_scl)\n",
    "x_test=pd.DataFrame(data=x_test_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "################Creating Function to fit and evaluate the data###################\n",
    "def fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS=100, BATCH_SIZE=1000):\n",
    "    results = model.fit(t_x, t_y, epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
    "              verbose=1, validation_split=0.1)  \n",
    "    print(\"Val Score: \", model.evaluate(val_x, val_y))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train[['B','C5','C10', 'C15', 'C20', 'C25', 'C30', 'C35', 'C40', 'A5', 'A10', 'A15', 'A20', 'A25', 'A30', 'A35', 'A40', 'N5', 'N10', 'N15', 'N20', 'N25', 'N30', 'N35', 'N40']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c25277681bb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNoise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "#############Creating loop for each column in y_train#################\n",
    "from pandas import ExcelWriter\n",
    "accuracy = []\n",
    "f_score = []\n",
    "y_pred_list = []\n",
    "\n",
    "from keras.layers import GaussianNoise\n",
    "t=y_train.columns\n",
    "count=0\n",
    "for i in range(y_train.shape[1]):\n",
    "    temp = \"\"\n",
    "    temp1 = \"\"\n",
    "    y_train_1=y_train[t[i]]\n",
    "    y_train_1=pd.DataFrame(y_train_1)\n",
    "    model = Sequential()\n",
    "    # in the first layer, you must specify the expected input data shape:\n",
    "    # here, 43-dimensional vectors.\n",
    "    model.add(Dense(64, activation='relu', input_dim=22))\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "    \n",
    "    model.add(Dense(512, activation = 'linear'))\n",
    "\n",
    "    #sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    n_folds=10\n",
    "    #save the model history in a list after fitting so that we can plot later\n",
    "    model_history = [] \n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"Training on Fold: \",i+1)\n",
    "        t_x, val_x, t_y, val_y = train_test_split(x_train, y_train_1, test_size=0.1,\n",
    "                                                  random_state = np.random.randint(1,1000, 1)[0])\n",
    "        model_history.append(fit_and_evaluate(t_x, val_x, t_y, val_y, 2,1000))\n",
    "        score = model.evaluate(x_test,y_test,batch_size=1000)\n",
    "        temp += str(score[1]) + \",\"\n",
    "        y_pred=model.predict_classes(x_test, verbose=0)\n",
    "        \n",
    "        f1 = f1_score(y_test, y_pred, average=\"micro\")\n",
    "        temp1 += str(f1) + \",\"\n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "    \n",
    "    accuracy.append(temp)\n",
    "    f_score.append(temp1)\n",
    "    \n",
    "df11 = pd.DataFrame({'B': y_pred_list[0], 'C5': y_pred_list[1], 'C10': y_pred_list[2], 'C15': y_pred_list[3], 'C20': y_pred_list[4], 'C25': y_pred_list[5], 'C30': y_pred_list[6], 'C35': y_pred_list[7], 'C40': y_pred_list[8], 'A5': y_pred_list[9], 'A10': y_pred_list[10], 'A15': y_pred_list[11], 'A20': y_pred_list[12], 'A25': y_pred_list[13], 'A30': y_pred_list[14], 'A35': y_pred_list[15], 'A40': y_pred_list[16], 'N5': y_pred_list[17], 'N10': y_pred_list[18], 'N15': y_pred_list[19], 'N20': y_pred_list[20], 'N25': y_pred_list[21], 'N30': y_pred_list[22], 'N35': y_pred_list[23], 'N40': y_pred_list[24]})\n",
    "writer = ExcelWriter(\"b_prediction.xlsx\")\n",
    "df11.to_excel(writer, 'Sheet1', index=False)\n",
    "writer.save()\n",
    "\n",
    "print(\"accuracy\")\n",
    "print(accuracy)\n",
    "print(\"f-score\")\n",
    "print(f_score)\n",
    "\n",
    "data_a = []\n",
    "for i in range(25):\n",
    "    data_a.append(list(map(float, accuracy[i].split(\",\")[:10])))\n",
    "    \n",
    "data_b = []\n",
    "\n",
    "for i in range(len(data_a)):\n",
    "    temp = data_a[i]\n",
    "    temp.append(statistics.mean(temp))\n",
    "    temp.append(statistics.stdev(temp))\n",
    "    data_b.append(temp)\n",
    "    \n",
    "df11 = pd.DataFrame({'N1': data_b[0], 'N2': data_b[1], 'N3': data_b[2], 'N4': data_b[3], 'N5': data_b[4], 'N6': data_b[5], 'N7': data_b[6], 'N8': data_b[7], 'N9': data_b[8], 'N10': data_b[9], 'N11': data_b[10], 'N12': data_b[11], 'N13': data_b[12], 'N14': data_b[13], 'N15': data_b[14], 'N16': data_b[15], 'N17': data_b[16], 'N18': data_b[17], 'N19': data_b[18], 'N20': data_b[19], 'N21': data_b[20], 'N22': data_b[21], 'N23': data_b[22], 'N24': data_b[23], 'N25': data_b[24]})\n",
    "writer = ExcelWriter(\"performance_b_a.xlsx\")\n",
    "df11.to_excel(writer, 'Sheet1', index=False)\n",
    "writer.save()\n",
    "\n",
    "\n",
    "data_a = []\n",
    "for i in range(25):\n",
    "    data_a.append(list(map(float, f_score[i].split(\",\")[:10])))\n",
    "    \n",
    "data_b = []\n",
    "\n",
    "for i in range(len(data_a)):\n",
    "    temp = data_a[i]\n",
    "    temp.append(statistics.mean(temp))\n",
    "    temp.append(statistics.stdev(temp))\n",
    "    data_b.append(temp)\n",
    "    \n",
    "df11 = pd.DataFrame({'N1': data_b[0], 'N2': data_b[1], 'N3': data_b[2], 'N4': data_b[3], 'N5': data_b[4], 'N6': data_b[5], 'N7': data_b[6], 'N8': data_b[7], 'N9': data_b[8], 'N10': data_b[9], 'N11': data_b[10], 'N12': data_b[11], 'N13': data_b[12], 'N14': data_b[13], 'N15': data_b[14], 'N16': data_b[15], 'N17': data_b[16], 'N18': data_b[17], 'N19': data_b[18], 'N20': data_b[19], 'N21': data_b[20], 'N22': data_b[21], 'N23': data_b[22], 'N24': data_b[23], 'N25': data_b[24]})\n",
    "writer = ExcelWriter(\"performance_b_f.xlsx\")\n",
    "df11.to_excel(writer, 'Sheet1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17535\n"
     ]
    }
   ],
   "source": [
    "print(len(val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
